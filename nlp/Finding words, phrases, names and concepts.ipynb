{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0403e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06c4a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the English nlp object\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5fb21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a text\n",
    "doc = nlp(\"I like tree kangaroos and narwhals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7340e350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like tree kangaroos and narwhals\n"
     ]
    }
   ],
   "source": [
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9987c79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree kangaroos\n"
     ]
    }
   ],
   "source": [
    "# A slice of the Doc for \"tree kangaroos\"\n",
    "tree_kangaroos = doc[2:4]\n",
    "print(tree_kangaroos.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a1ae985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree kangaroos and narwhals\n"
     ]
    }
   ],
   "source": [
    "# A slice of the Doc for \"tree kangaroos and narwhals\" (without the \".\")\n",
    "tree_kangaroos_and_narwhals = doc[2:6]\n",
    "print(tree_kangaroos_and_narwhals.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4aaa8",
   "metadata": {},
   "source": [
    "In this example, you’ll use spaCy’s Doc and Token objects, and lexical attributes to find percentages in a text. You’ll be looking for two subsequent tokens: a number and a percent sign."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c18262",
   "metadata": {},
   "source": [
    "Use the like_num token attribute to check whether a token in the doc resembles a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3de0b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\n",
    "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
    "    \"Now less than 4% are.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9536bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990\n",
      "id index is 1\n",
      "next symbol ,\n",
      "60\n",
      "id index is 5\n",
      "next symbol %\n",
      "is equal to %\n",
      "4\n",
      "id index is 20\n",
      "next symbol %\n",
      "is equal to %\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the tokens in the doc\n",
    "for token in doc:\n",
    "    # Check if the token resembles a number\n",
    "    if token.like_num:\n",
    "        print(token.text)\n",
    "        print(f'id index is {token.i}')\n",
    "        \n",
    "        #get the next symbol \n",
    "        print(f'next symbol {doc[token.i + 1]}')\n",
    "        if doc[token.i + 1].text == '%':\n",
    "            print(\"is equal to %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32fdd14",
   "metadata": {},
   "source": [
    "The pipelines we’re using in this course are already pre-installed. For more details on spaCy’s trained pipelines and how to install them on your machine, see the documentation.\n",
    "\n",
    "Use spacy.load to load the small English pipeline \"en_core_web_sm\".\n",
    "Process the text and print the document text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7eebb0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the \"en_core_web_sm\" pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18fe7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04224890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d91cd3",
   "metadata": {},
   "source": [
    "Process the text and create a doc object. <br>\n",
    "Iterate over the doc.ents and print the entity text and label_ attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4844ba5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Companies, agencies, institutions, etc.\n",
      "first ORDINAL\n",
      "\"first\", \"second\", etc.\n",
      "U.S. GPE\n",
      "Countries, cities, states\n",
      "$1 trillion MONEY\n",
      "Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and its label\n",
    "    print(ent.text, ent.label_)\n",
    "    print(spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db2df199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Apple, first, U.S., $1 trillion)\n"
     ]
    }
   ],
   "source": [
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab1f4bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "David is  23 the best man on the world"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"David is  23 the best man on the world\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(txt)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa032512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David PERSON\n",
      "Monetary values, including unit\n",
      "23 CARDINAL\n",
      "Monetary values, including unit\n",
      "(David, 23)\n"
     ]
    }
   ],
   "source": [
    "for e in doc.ents:\n",
    "    print(e.text, e.label_)\n",
    "    print(spacy.explain(ent.label_))\n",
    "    \n",
    "print(doc.ents)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc87563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and its label\n",
    "    print(ent.text, ent.label_)\n",
    "    print(spacy.explain(ent.label_))\n",
    "    print(\"DSA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd9e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f108e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3be2fe86",
   "metadata": {},
   "source": [
    "Models are statistical and not always right. Whether their predictions are correct depends on the training data and the text you’re processing. Let’s take a look at an example.\n",
    "\n",
    "Process the text with the nlp object.\n",
    "Iterate over the entities and print the entity text and label.\n",
    "Looks like the model didn’t predict “iPhone X”. Create a span for those tokens manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a054324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Companies, agencies, institutions, etc.\n",
      "Missing entity: iPhone X\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and label\n",
    "    print(ent.text, ent.label_)\n",
    "    print(spacy.explain(ent.label_))\n",
    "\n",
    "# Get the span for \"iPhone X\"\n",
    "iphone_x = doc[1:3]\n",
    "\n",
    "# Print the span text\n",
    "print(\"Missing entity:\", iphone_x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6239acd3",
   "metadata": {},
   "source": [
    "Let’s try spaCy’s rule-based Matcher. You’ll be using the example from the previous exercise and write a pattern that can match the phrase “iPhone X” in the text.\n",
    "\n",
    "Import the Matcher from spacy.matcher.\n",
    "Initialize it with the nlp object’s shared vocab.\n",
    "Create a pattern that matches the \"TEXT\" values of two tokens: \"iPhone\" and \"X\".\n",
    "Use the matcher.add method to add the pattern to the matcher.\n",
    "Call the matcher on the doc and store the result in the variable matches.\n",
    "Iterate over the matches and get the matched span from the start to the end index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eee8ecdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['iPhone X']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Upcoming iPhone X release date leaked as Apple reveals pre-orders\")\n",
    "\n",
    "# Initialize the Matcher with the shared vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Create a pattern matching two tokens: \"iPhone\" and \"X\"\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"IPHONE_X_PATTERN\", [pattern])\n",
    "\n",
    "# Use the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6089e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4fbd62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\" Mehmed is 29 years old.He works in Haemimont, also he was worked on Haemimont and Haemimont. Maria is the best and Maria is with Deyvid.\n",
    "    David is the man who believe in his farm.Be nice David\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9fb9a0e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "75c6b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mehmed PERSON\n",
      "People, including fictional\n",
      "29 years old DATE\n",
      "Absolute or relative dates or periods\n",
      "Haemimont GPE\n",
      "Countries, cities, states\n",
      "Haemimont GPE\n",
      "Countries, cities, states\n",
      "Haemimont GPE\n",
      "Countries, cities, states\n",
      "Maria PERSON\n",
      "People, including fictional\n",
      "Maria PERSON\n",
      "People, including fictional\n",
      "Deyvid PERSON\n",
      "People, including fictional\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(txt)\n",
    "\n",
    "\n",
    "for e in doc.ents:\n",
    "    print(e.text, e.label_)\n",
    "    print(spacy.explain(e.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4092e6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['Haemimont', 'Haemimont', 'Haemimont']\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"TEXT\": \"Haemimont\"}]  #\n",
    "matcher.add(\"Haemimont\", [pattern])\n",
    "# Use the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
