import numpy as np
import pandas as pd
import collections


def entropy(y):
    """ Entropy measures the degree of uncertainty,
     impurity or disorder of a random variable

    :param target: (list) target values
    :return: (float)  entropy of the array
    """

    counter = collections.Counter(y)
    p = np.array(list(counter.values())) / len(y)
    return -np.sum(p * np.log2(p))


def information_gain(y, mask, func=entropy):
    """Information gain is used for determining the best
    features/attributes that render maximum information about a class.

    :param y: (list) target values
    :param mask:(list of booleans) used for splitting the data
    :param func: (function) function for measurements of impurity/uncertainty
    :return: (float) Information Gain
    """
    if isinstance(y, pd.Series):
        y_right = y[mask]
        y_left = y[-mask]
        size = len(y)
        w_right, w_left = len(y_right) / size, len(y_left) / size
        return entropy(y) - (w_right * entropy(y_right) + w_left * w_left)

    else:
        raise TypeError("y must be a Pandas Series")


def best_split_value(series, y, split_type):
    values = series.unique()
    inf_gain_values = []
    feature_values = []

    for val in values:
        if split_type == '<=':
            mask = series < val
        else:
            mask = series >= val

        i_g = information_gain(y, mask, func=entropy)
        inf_gain_values.append(i_g)
        feature_values.append(val)

    max_inf_gain = np.max(inf_gain_values)
    index = inf_gain_values.index(max_inf_gain)
    best_feature_value = feature_values[index]

    return best_feature_value, max_inf_gain


def split_data(x, y, question):
    feature, value = list(question.split(Node.split_type))
    if Node.split_type == '<':
        mask = x[feature] < float(value)
    else:
        mask = x[feature] >= value

    x_left = x[mask]
    x_right = x[-mask]
    y_left = y[mask]
    y_right = y[-mask]

    return x_left, y_left, x_right, y_right


class Node:
    split_type = '<'

    def __init__(self):
        self.left_interior = None
        self.right_interior = None
        self.data = None
        self.question = None

    @staticmethod
    def best_split(x, y):
        k = x.apply(best_split_value, y=y.squeeze(), split_type=Node.split_type)
        gini_values = k.iloc[1]  # index 1 refers to gini values
        max_value = gini_values.max()
        index = np.where(gini_values == max_value)[0][0]

        val = k.iloc[:, [index]].loc[0]
        best_value = val.values[0]
        best_feature = val.index[0]
        return best_feature, best_value

    def has_left_child(self):
        return True if self.left_child else False

    def has_right_child(self):
        return True if self.right_child else False


def verify(x, y):
    if (isinstance(x, pd.DataFrame) or isinstance(x, pd.DataFrame)) and (
            isinstance(x, pd.DataFrame) or isinstance(y, pd.Series)):
        pass
    else:
        raise TypeError("x and y must be Pandas DataFrame")


class DecisionTree:

    def __init__(self, max_depth=None, min_infromation_gain=None):
        self.max_depth = max_depth
        self.min_info_g = min_infromation_gain
        self.root = None
        self.right_depth = 0;
        self.left_depth = 0

    def train(self, x, y):
        verify(x, y)
        global root_global
        root_global = self.root
        self.root = self.generate_decision_node(x, y)
        print(self.root.question)

    def generate_decision_node(self, x, y):
        """

        :return: Node
        """

        node = Node()

        feature, value = Node.best_split(x, y)
        question = str(feature) + Node.split_type + str(value)
        node.question = question
        x_left, y_left, x_right, y_right = split_data(x, y, question)

        if self.max_depth and self.left_depth == self.max_depth:
            pass
        else:
            self.left_depth += 1
            node.left_interior = self.generate_decision_node(x_left, y_left)

        if self.max_depth and self.right_depth == self.max_depth:
            pass
        else:
            self.right_depth += 1
            node.right_interior = self.generate_decision_node(x_right, y_right)

        return node

    def predict(self, x):
        pass

    def accuracy(self, x, y):
        pass

    def _generate_tree(self):
        pass


A = np.array([1, 2, 3])

data = pd.read_csv("../../../resources/data/500_Person_Gender_Height_Weight_Index.csv")

data.drop('Gender', axis=1, inplace=True)
data['obese'] = (data.Index > 4).astype('int')
data.drop('Index', axis=1, inplace=True)
x = data.drop(['obese'], axis=1)
y = data[['obese']]

tree = DecisionTree(max_depth=5)

tree.train(x, y)
